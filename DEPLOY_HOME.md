# ðŸ  Karina AI â€” Ð Ð°Ð·Ð²Ñ‘Ñ€Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ðµ Ð½Ð° Ð´Ð¾Ð¼Ð°ÑˆÐ½ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€Ðµ (Ubuntu 22.04)

## ðŸ“‹ Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ

- **CPU**: 4+ ÑÐ´Ñ€Ð° (Ð»ÑƒÑ‡ÑˆÐµ 8)
- **RAM**: 16GB+ (Ð´Ð»Ñ LLM 7B)
- **GPU**: ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ (NVIDIA Ð´Ð»Ñ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ)
- **Ð”Ð¸ÑÐº**: 50GB+ (LLM + Ð´Ð°Ð½Ð½Ñ‹Ðµ)
- **OS**: Ubuntu 22.04 LTS

---

## ðŸš€ Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ€Ñ‚

### 1. ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
```bash
sudo apt update && sudo apt upgrade -y
```

### 2. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Docker
```bash
sudo apt install docker.io docker-compose -y
sudo usermod -aG docker $USER
# ÐŸÐµÑ€ÐµÐ»Ð¾Ð³Ð¸Ð½ÑŒÑÑ Ð´Ð»Ñ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ
```

### 3. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ollama (Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ LLM)
```bash
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull mistral:7b  # 4.1GB Ð¼Ð¾Ð´ÐµÐ»ÑŒ
```

### 4. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° PostgreSQL + pgvector
```bash
sudo apt install postgresql postgresql-contrib -y

# pgvector Ð´Ð»Ñ RAG
sudo apt install postgresql-server-dev-all -y
cd /tmp
git clone --branch v0.5.0 https://github.com/pgvector/pgvector.git
cd pgvector
make
sudo make install
```

### 5. ÐšÐ»Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
```bash
cd ~
git clone https://github.com/your-username/tg-emoji-status-bot.git
cd tg-emoji-status-bot
```

### 6. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ .env Ñ„Ð°Ð¹Ð»Ð°
```bash
cp .env.example .env
nano .env  # ÐžÑ‚Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÐ¹ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ
```

### 7. Ð—Ð°Ð¿ÑƒÑÐº
```bash
# Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹
pip3 install -r requirements.txt

# Ð—Ð°Ð¿ÑƒÑÐº Ð±Ð¾Ñ‚Ð°
python3 main.py
```

---

## ðŸ”§ Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°

### PostgreSQL

```sql
-- Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸ Ð±Ð°Ð·Ñ‹
sudo -u postgres psql

CREATE DATABASE karina_db;
CREATE USER karina_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE karina_db TO karina_user;
\q

# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ health_records
sudo -u postgres psql karina_db

CREATE TABLE IF NOT EXISTS health_records (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    confirmed BOOLEAN DEFAULT true,
    timestamp TIMESTAMPTZ DEFAULT NOW(),
    date DATE DEFAULT CURRENT_DATE,
    time TIME DEFAULT CURRENT_TIME,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS memories (
    id BIGSERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    embedding vector(1024),
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Ð˜Ð½Ð´ÐµÐºÑÑ‹
CREATE INDEX idx_health_date ON health_records(date DESC);
CREATE INDEX idx_health_user ON health_records(user_id);
CREATE INDEX idx_memories_embedding ON memories USING ivfflat (embedding vector_cosine_ops);

\q
```

### Ollama API

Ð¡Ð¾Ð·Ð´Ð°Ð¹ Ñ„Ð°Ð¹Ð» `brains/ollama_client.py`:

```python
import httpx
import logging

logger = logging.getLogger(__name__)

OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "mistral:7b"

async def generate_text(prompt: str, system: str = None) -> str:
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½ÑƒÑŽ Ollama"""
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.8,
            "top_p": 0.9
        }
    }
    
    if system:
        payload["system"] = system
    
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(OLLAMA_URL, json=payload)
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '')
            else:
                logger.error(f"Ollama error: {response.status_code}")
                return None
    except Exception as e:
        logger.error(f"Ollama request failed: {e}")
        return None
```

---

## ðŸ“ .env Ñ„Ð°Ð¹Ð»

```bash
# Telegram
API_ID=12345678
API_HASH=your_api_hash
SESSION_STRING=your_session_string
KARINA_BOT_TOKEN=your_bot_token

# AI (Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹)
USE_LOCAL_AI=true
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b

# Ð•ÑÐ»Ð¸ Ñ…Ð¾Ñ‡ÐµÑˆÑŒ Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Mistral (Ñ€ÐµÐ·ÐµÑ€Ð²)
MISTRAL_API_KEY=your_key

# Database (Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ PostgreSQL)
DATABASE_URL=postgresql://karina_user:your_password@localhost:5432/karina_db
SUPABASE_URL=http://localhost:5432
SUPABASE_KEY=your_password

# Google Calendar
GOOGLE_CALENDAR_CREDENTIALS={"type":"service_account",...}

# Voice (Hugging Face)
HF_TOKEN=your_token

# Weather
WEATHER_API_KEY=your_key
WEATHER_CITY=Moscow

# User IDs
MY_TELEGRAM_ID=your_id
TARGET_USER_ID=target_id
```

---

## ðŸ³ Docker Compose (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)

Ð¡Ð¾Ð·Ð´Ð°Ð¹ `docker-compose.yml`:

```yaml
version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_DB: karina_db
      POSTGRES_USER: karina_user
      POSTGRES_PASSWORD: your_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped
    # Ð”Ð»Ñ GPU:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  karina-bot:
    build: .
    environment:
      - DATABASE_URL=postgresql://karina_user:your_password@postgres:5432/karina_db
      - OLLAMA_URL=http://ollama:11434
    volumes:
      - ./data:/app/data
    depends_on:
      - postgres
      - ollama
    restart: unless-stopped

volumes:
  postgres_data:
  ollama_data:
```

Ð—Ð°Ð¿ÑƒÑÐº:
```bash
docker-compose up -d
```

---

## ðŸ” ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³

### Ð›Ð¾Ð³Ð¸
```bash
# Ð‘Ð¾Ñ‚
journalctl -u karina-bot -f

# Ollama
journalctl -u ollama -f

# PostgreSQL
sudo tail -f /var/log/postgresql/postgresql-*.log
```

### Ð ÐµÑÑƒÑ€ÑÑ‹
```bash
# CPU/RAM
htop

# GPU (ÐµÑÐ»Ð¸ NVIDIA)
nvidia-smi

# Ð”Ð¸ÑÐº
df -h
```

---

## ðŸ›¡ Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ

### Firewall
```bash
sudo ufw enable
sudo ufw allow 22/tcp  # SSH
sudo ufw allow 5432/tcp  # PostgreSQL (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾!)
# ÐÐµ Ð¾Ñ‚ÐºÑ€Ñ‹Ð²Ð°Ð¹ 11434 Ð½Ð°Ñ€ÑƒÐ¶Ñƒ!
```

### ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑÑ‚Ð°Ñ€Ñ‚
```bash
# Ð¡Ð¾Ð·Ð´Ð°Ð¹ systemd ÑÐµÑ€Ð²Ð¸Ñ
sudo nano /etc/systemd/system/karina-bot.service
```

```ini
[Unit]
Description=Karina AI Bot
After=network.target postgresql.service ollama.service

[Service]
Type=simple
User=your_user
WorkingDirectory=/home/your_user/tg-emoji-status-bot
ExecStart=/usr/bin/python3 /home/your_user/tg-emoji-status-bot/main.py
Restart=always

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reload
sudo systemctl enable karina-bot
sudo systemctl start karina-bot
sudo systemctl status karina-bot
```

---

## ðŸ“Š Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ: Railway vs Ð”Ð¾Ð¼Ð°ÑˆÐ½Ð¸Ð¹ ÑÐµÑ€Ð²ÐµÑ€

| ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ | Railway | Ð”Ð¾Ð¼Ð°ÑˆÐ½Ð¸Ð¹ ÑÐµÑ€Ð²ÐµÑ€ |
|----------|---------|-----------------|
| **Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ** | $5-20/Ð¼ÐµÑ | ~$2-5/Ð¼ÐµÑ (ÑÐ»ÐµÐºÑ‚Ñ€Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾) |
| **CPU** | ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¾ | ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð´Ð¾ÑÑ‚ÑƒÐ¿ |
| **RAM** | ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¾ | ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð´Ð¾ÑÑ‚ÑƒÐ¿ |
| **LLM** | Ð¢Ð¾Ð»ÑŒÐºÐ¾ API | Ð›ÑŽÐ±Ð°Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ |
| **Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ** | ÐžÐ±Ð»Ð°ÐºÐ¾ | ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ |
| **ÐÐ°Ð´Ñ‘Ð¶Ð½Ð¾ÑÑ‚ÑŒ** | 99.9% | Ð—Ð°Ð²Ð¸ÑÐ¸Ñ‚ Ð¾Ñ‚ Ñ‚ÐµÐ±Ñ |
| **ÐœÐ°ÑÑˆÑ‚Ð°Ð±** | Ð›ÐµÐ³ÐºÐ¾ | ÐÑƒÐ¶Ð½Ð¾ ÑÐ°Ð¼Ð¾Ð¼Ñƒ |

---

## ðŸŽ¯ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸

### Ð”Ð»Ñ Ð½Ð°Ñ‡Ð°Ð»Ð°:
1. **Ollama + mistral:7b** â€” Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð´Ð»Ñ Ð½Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¹
2. **PostgreSQL Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾** â€” Ð²Ð¼ÐµÑÑ‚Ð¾ Supabase
3. **Docker** â€” Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñ‹ Ñ€Ð°Ð·Ð²Ñ‘Ñ€Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ñ

### Ð”Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐµÐ½Ð°:
1. **vLLM** â€” Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ Ollama
2. **GPU** â€” NVIDIA RTX 3060+ (12GB VRAM)
3. **Reserve proxy** â€” Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ð¸Ð·Ð²Ð½Ðµ

---

## ðŸ†˜ Troubleshooting

### Ollama Ð½Ðµ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ
```bash
ollama serve  # Ð’Ñ€ÑƒÑ‡Ð½ÑƒÑŽ
journalctl -u ollama -f  # Ð›Ð¾Ð³Ð¸
```

### PostgreSQL Ð½Ðµ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ÑÑ
```bash
sudo systemctl status postgresql
sudo tail -f /var/log/postgresql/postgresql-*.log
```

### Ð‘Ð¾Ñ‚ Ð½Ðµ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚
```bash
sudo systemctl status karina-bot
sudo journalctl -u karina-bot -f
```

### ÐÐµÑ…Ð²Ð°Ñ‚ÐºÐ° RAM
```bash
# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¼ÐµÐ½ÑŒÑˆÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
ollama pull mistral:7b-instruct-q4_K_M  # 2.5GB Ð²Ð¼ÐµÑÑ‚Ð¾ 4.1GB
```

---

**Ð“Ð¾Ñ‚Ð¾Ð²Ð¾!** ðŸŽ‰ Ð¢ÐµÐ¿ÐµÑ€ÑŒ Karina Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð½Ð° Ñ‚Ð²Ð¾Ñ‘Ð¼ ÑÐµÑ€Ð²ÐµÑ€Ðµ Ð±ÐµÐ· Ð»Ð¸Ð¼Ð¸Ñ‚Ð¾Ð²!

(karina) ai@ai-node:~/tg-emoji-status-bot$ git pull origin main
remote: Enumerating objects: 426, done.
remote: Counting objects: 100% (426/426), done.
remote: Compressing objects: 100% (182/182), done.
remote: Total 426 (delta 230), reused 416 (delta 220), pack-reused 0 (from 0)
Receiving objects: 100% (426/426), 1.38 MiB | 55.00 KiB/s, done.
Resolving deltas: 100% (230/230), done.
From https://github.com/RivixXx/tg-emoji-status-bot
 * branch            main       -> FETCH_HEAD
 + 7925fd1...7775ea7 main       -> origin/main  (forced update)
hint: You have divergent branches and need to specify how to reconcile them.
hint: You can do so by running one of the following commands sometime before
hint: your next pull:
hint:
hint:   git config pull.rebase false  # merge (the default strategy)
hint:   git config pull.rebase true   # rebase
hint:   git config pull.ff only       # fast-forward only
hint:
hint: You can replace "git config" with "git config --global" to set a default
hint: preference for all repositories. You can also pass --rebase, --no-rebase,
hint: or --ff-only on the command line to override the configured default per
hint: invocation.
fatal: Need to specify how to reconcile divergent branches.